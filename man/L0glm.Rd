% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/L0glm.R
\name{L0glm}
\alias{L0glm}
\alias{L0glm.fit}
\alias{glm.iwls}
\title{Fitting Constrained L0 Penalized Generalized Linear Models}
\usage{
L0glm(formula, data = NULL, weights = rep(1, length(y)),
  family = gaussian(identity), start = NULL, contrasts = NULL,
  lambda = 0, no.pen = 0, nonnegative = FALSE, normalize = TRUE,
  control.l0 = list(), control.iwls = list(), control.fit = list(),
  post.filter.fn = function(u) return(u), tune.meth = "none",
  tune.crit = "bic", train.vs.val = 0.9, seed = NULL,
  verbose = TRUE)

L0glm.fit(X, y, weights = rep(1, length(y)),
  family = poisson(identity), lambda = 0, start = NULL,
  nonnegative = FALSE, normalize, post.filter.fn = function(u)
  return(u), control.l0 = list(maxit = 100, rel.tol = 1e-04, delta =
  1e-05, gamma = 2, warn = FALSE), control.iwls = list(maxit = 1, rel.tol
  = 1e-04, thresh = 1e-05, warn = FALSE), control.fit = list(maxit = 10,
  block.size = NULL, tol = 1e-07))

glm.iwls(X, y, weights, family, start = NULL, lambda = rep(0, ncol(X)),
  nonnegative = FALSE, control.iwls = list(maxit = 1, rel.tol = 1e-04,
  thresh = 1e-05, warn = FALSE), control.fit = list(maxit = 10,
  block.size = NULL, tol = 1e-07), converged_set = rep(FALSE, ncol(X)))
}
\arguments{
\item{formula}{a formula object describing the model to fit. See \code{\link{stats::formula}}
for more details.}

\item{data}{the data from which to extract the covariates called in the formula. If \code{NULL},
data is retrieved from the environment associated with the formula.}

\item{weights}{a vector of observation weights ("prior weights") of length
\code{n}.}

\item{family}{a description of the error distribution and link function to be
used in the model. This can be a character string naming a family function, a
family function or the result of a call to a family function. (See
\code{stats::family} for details of family functions.)}

\item{start}{a vector of starting values for the coefficients to estimate.
Must be of length \code{p}.}

\item{contrasts}{a list specifying the contrasts to use for the covariates when building the
design matrix. Default are the contrasts generated by \code{\link{contrasts}}.}

\item{lambda}{either a scalar, a vector of numerics, or a character (see details). Set
\code{lambda = 0} to disable penalization.}

\item{no.pen}{a vector of coefficient indices (intercept excluded) that should \strong{not}
be penalized.}

\item{nonnegative}{a logical indicating whether nonnegativity constraints should be applied.}

\item{normalize}{should the covariate matrix be normalized with the L2 norm (Euclidean norm)?
It is advised to use normalization unless the covariates were measures on a
similar unit scale.}

\item{control.l0}{list of parameters controling the L0 penalty loop (see details). The list
should contain the following elements:
\itemize{
\item{\code{maxit}: maximum number of iterations. Set to 1 for ridge penalty
(if \code{start == NULL}) or adaptive ridge penalty (if \code{start} != NULL).}
\item{\code{rel.tol}: coefficients are update until the relative difference
between two iteration is smaller than this threshold. The relative difference
is defined as
\eqn{2 \frac{|coef_i^{(k-1)} - coef_i^{(k)}|}{coef_i^{(k-1)} + coef_i^{(k)}}}}
\item{\code{delta}, \code{gamma}: parameters for computing the adaptive
weights during the penalization.}
\item{\code{warn}: should warnings from the AR iteration be produced ?}
}
Missing values will be filled with defaults (see \code{\link{control.l0.gen}})}

\item{control.iwls}{list of parameters controling the IWLS loop (see details). The list should
contain the following elements:
\itemize{
\item{\code{maxit}: maximum number of iterations}
\item{\code{rel.tol}: coefficients are update until the relative difference
between two iteration is smaller than this threshold. The relative difference
is defined as
\eqn{2 \frac{|coef_i^{(k-1)} - coef_i^{(k)}|}{coef_i^{(k-1)} + coef_i^{(k)}}}}
\item{\code{thresh}: a threshold under which the fitted coefficients are
clipped to 0.}
\item{\code{warn}: should warnings from the IWLS iteration be produced ?}
}
Missing values will be filled with defaults (see \code{\link{control.iwls.gen}})}

\item{control.fit}{list of parameters controling the core fitting algoritm (see details). The
list should contain the following elements:
\itemize{
\item{\code{maxit}: maximum number of iterations}
\item{\code{block.size}: number of covariates to fit simultaneously. If
\code{block.size < p}, the fit is performed in different blocks which is
updated cyclically. }
\item{\code{tol}: stop iteration when the difference in coefficients between
iterations is smaller than this threshold. The coefficient difference is
defined as:
\eqn{\frac{\|coefs^{(k-1)} - coefs^{(k)}}{\|coefs^{(k-1)}\|}}}
}
Missing values will be filled with defaults (see \code{\link{control.fit.gen}})}

\item{post.filter.fn}{A function that performs post filtering to the coefficients at the end of the
fit. It should require a single argument that is the vector of coefficients.
Note that lambda tuning will be performed with the processed coefficients, so
the selected lambda will be influence by the filtering step. Default: no
filtering.}

\item{tune.meth}{lambda selection method (see details). It should be one of \code{"none"},
\code{"IC"}, \code{"trainval"}, \code{"loocv"}, \code{"k-fold"} (where
k should be a numeric indicating the number of folds to use).}

\item{tune.crit}{the criterion based on which to select the optimal lambda. Should be one of
\code{"all"}, \code{"bic"}, \code{"aic"}, \code{"loglik"}, \code{"loocv"},
\code{"rss"}, \code{"aicc"}, \code{"ebic"}, \code{"hq"}, \code{"ric"},
\code{"mric"}, \code{"cic"}, \code{"bicg"}, \code{"bicq"})}

\item{train.vs.val}{a value between \code{1/n} and \code{1-1/n} which indicates the proportion
of observations that will be allocated to the training set. This is used only
in the case that \code{tune.meth == "trainval"}, ignored otherwise.}

\item{seed}{a seed to use. Used only for the \code{"k-fold"} CV and training validation set
(\code{"trainval"}) tuning methods.}

\item{verbose}{print algorithm progression to console ?}

\item{converged_set}{a vector of length \code{p} with logicals indicating whether the
corresponding coefficient already converged (\code{TRUE}) or not
(\code{FALSE}).}
}
\value{
\code{L0glm} returns an "L0glm" object which contains the following
elements:
\item{\code{call}}{The call that produced this object.}
\item{\code{coefficients}}{a vector of fitted coefficients.}
\item{\code{constraint}}{the constrained used for fitting. Either "none" if
no constraint was applied or "nonneg" for nonnegative fits.}
\item{\code{converged.iwls}}{Did the last iteration of IWLS converged?}
\item{\code{converged.l0}}{Did the adaptive ridge converged?}
\item{\code{deviance}}{a list containing degrees of freedom and deviance
for the fitted model and the null model. The goodness of fit is computed as:
\eqn{D^2 = 1 - \frac{D_{res}}{D_{null}}}}
\item{\code{df}}{a list containing the \code{edf} effective degrees of freedom,
and \code{rdf} residual degree of freedom of the fitted model.}
\item{\code{eta}}{a vector with the fitted response on the link scale.}
\item{\code{family}}{The error structure used to fit the data.}
\item{\code{fitted.values}}{a vector with the fitted response.}
\item{\code{IC}}{a vector with IC values and other goodness of fit criteria.
Currently implemented are: \code{loglik}, \code{rss}, \code{aic}, \code{aicc},
\code{bic}, \code{ebic}, \code{hq}, \code{ric}, \code{mric}, \code{cic},
\code{bicg}, \code{bicq}.}
\item{\code{iter.iwls}}{A vector of length \code{iter.l0} containing the
number of iterations performed for every IWLS fit.}
\item{\code{iter.l0}}{The number of adaptive ridge iterations.}
\item{\code{lambda}}{The lambda used for the the adaptive ridge. This is a
vector of length \code{p} which may contain zeros for unpenalized coefficients.}
\item{\code{lambda.tune}}{a list generated during lambda tuning (if required).
The list contains the sequence of lambdas, the estimated coefficients for
every lambda (except if \code{tune.meth == "k-fold"}), the IC associated to
every lambda, and the selected lambda.}
\item{\code{lambda.w}}{The converged lambda weights from the adaptive ridge
iteration. This is a vector of length \code{p} with coefficient specific
weights.}
\item{\code{prior.coefficients}}{a vector with the supplied prior values of the
coefficients. NULL if no prior was supplied.}
\item{\code{prior.weights}}{a vector with the initial observation weights}
\item{\code{residuals}}{a vector of residuals.}
\item{\code{timing}}{time (in sec) taken for fitting the model (after lambda tuning).}
\item{\code{weights}}{a vector of converged IWNNLS weights. This is a vector
of length \code{n}.}
}
\description{
Fit a generalized linear model with nonnegativity contraints and ridge, adaptive ridge,
or best subset (L0) penalty on the coefficients. The function uses an iteratively reweighted
nonnegative least squares (IWNNLS) algorithm, which was adapted from the
regular IRLS algorithms to solve GLMs (McCullach & Nelder 1989).
}
\details{
\strong{Structure of the algorithm}

\code{L0glm} starts with lambda tuning (see below) and tries to select the
best lambda out of the serie of lambda supplied by the user, given a
tuning method and criterion. If a single lambda value is supplied, this
step is skipped. The best lambda is then used to fit the penalized GLM. The
algorithm contains 3 main nest loops. From high level to low level:
\itemize{
\item{\strong{Adaptive ridge for L0 penalty:} the L0 penalty is approximated
by iteratively fitting an adaptive ridge and update the penalty weights based
on the fitted coefficient from the previous update  (Frommlet et Nuel 2016).
The penalty weights are updated using the formula
\eqn{\frac{1}{(|\beta|^{\gamma} + \delta^{\gamma})}}.
When \code{control.l0$maxit == 1}, this boils down to a simple ridge penalty.
Furthermore, with \code{start != NULL}, an simple adaptive ridge is used where
\code{start} is considered as the coefficient priors.}
\item{\strong{GLM fitting using IWLS:} within every AR loop, a GLM is fit. If
the error family is Gaussian, this is a (nonnegative) least square regression.
For other error families and other link function than identity, the GLM is
solved using iteratively reweighted least squares (IWLS, McCullach & Nelder
1989). To include ridge regularization, the covariate matrix is augmented
with the diagonal matrix \eqn{\sqrt{\lambda} \bm{I}}, and the response is
augmented with 0s accordingly.}
\item{\strong{Block-wise (NN)LS fitting:} TODO needed?}
}

Information criteria and other goodness of fit of measures are computed based
on the fitted coefficients.

\strong{Lambda tuning}

Lambda can be specified in 3 ways:


\itemize{
\item{\strong{Scalar}: lambda is the penalty factor used for the ridge,
adaptive ridge, or best subset regression.}

\item{\strong{Numerical vector}: every value of lambda will be used as penalty
factor for the ridge, adaptive ridge, or best subset regression, separately.
The lambda that leads to the best fit according to the provided selection
method and  criteria is kept and used to fit the model. If \code{tune.meth} is set
to \code{"none"}, the fit will be performed with every lambda and hence the
\code{"L0glm"} object will contain an \code{p x length(lambda)} matrix of
coefficients and \code{n x length(lambda)} matrix of fitted values.}

\item{\strong{Character}}: In the case that L0 penalty is required (\emph{i.e.}
\code{control.l0$maxit > 1}), lambda can be supplied as the information
criterion to optimize. Possible values are \code{"aic"}, \code{"bic"},
\code{"hq"}, or \code{"bicq"}.
}

The lambda tuning can be performed using 3 different methods:
\itemize{
\item{When \code{tune.meth == "trainval"}, lambda is tuned using a training
and validation set. The training set will contain 90\% of the observations.
The best lambda is the lambda that leads to the highest performance according
to the IC measure computed on the validation set.}
\item{When \code{tune.meth == "IC"}, lambda is tuned on the full dataset. The
lambda associated with the best IC value will be selected. It is not
recommended using this method with \code{tune.crit == "rss"|"loglik"} since
it cannot overcome overfitting.}
\item{When \code{tune.meth == "k-fold"} (where \code{k} should be a numeric),
the lambda is tuned using k-fold cross-validation. The data is split in k
chunks where each chunk serves as a validation sets while the remaining data
serves as training set. The IC measure across folds are averaged. For LOOCV,
use \code{tune.meth == "IC"} and \code{tune.crit == "loocv"}.}
}

To avoid unnecessary computations, the algorithm finds the maximal lambda for
which all coefficients are 0. This is given by
\deqn{\lambda_{max} = \max_{i = 1,\dots,p}~ 1/2  (X^\top_i X_i)^{-1} (X^\top_i y)^2}
}
\section{Functions}{
\itemize{
\item \code{L0glm.fit}: fits an L0 penalized regression using the adaptive ridge algorithm (Frommlet
et Nuel 2016). The function contains minimal code for fitting the adaptive
ridge and is called by the higher level \code{L0glm}.

\item \code{glm.iwls}: fits a GLM using iteratively weighted least squares (McCullagh and Nelder 1989). Note that
\code{lambda} should be a vector of length \code{p} and no lambda tuning is
performed.
}}

\note{
When a lambda is supplied as vector with no tuning method (\code{tune.meth == "none"}),
the function returns an object of class \code{tune.L0glm}. This contains
\code{coefficients} (a \code{p} by \code{length(lambda)} matrix), \code{fitted.values}
(a \code{n} by \code{length(lambda)} matrix), \code{family}, and \code{prior.weights}.
}
\examples{
# Simulate data
sim <- simulate_spike_train()
X <- sim$X
y <- sim$y

# Case I: fit nonnegative identity link Poisson GLM with no penalty
L0glm1 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                lambda = 0, tune.meth = "none", nonnegative = TRUE,
                control.iwls = list(maxit = 100),
                control.l0 = list(maxit = 1, delta = 1E-2, gamma = 1.8))
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm1, a.true = sim$a,
                     main="Ground truth vs L0glm estimates")

# Case II: fit nonnegative identity link Poisson GLM with ridge penalty
L0glm2 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                lambda = 1, tune.meth = "none", nonnegative = TRUE,
                control.iwls = list(maxit = 100),
                control.l0 = list(maxit = 1))
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm2, a.true = sim$a,
                     main="Ground truth vs L0glm estimates (with ridge penalty)")

# Case III: fit nonnegative identity link Poisson GLM with adaptive ridge penalty
library(nnls)
a0 <- nnls(A = X*sqrt(1/(y+0.1)),
           b = y*sqrt(1/(y+0.1)))$x
L0glm3 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                start = a0, lambda = 1, tune.meth = "none", nonnegative = TRUE, normalize = FALSE,
                control.iwls = list(maxit = 100),
                control.l0 = list(maxit = 1))
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm3, a.true = sim$a,
                     main="Ground truth vs L0glm estimates (with adaptive ridge penalty)")

# Case IV: fit nonnegative identity link Poisson GLM with L0 penalty and a fixed
#          lambda (no lambda selection)
L0glm4 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                lambda = 1, tune.meth = "none", nonnegative = TRUE, normalize = FALSE)
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm4, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates")

\donttest{ # Code below is computationally costly
# Case V: fit nonnegative identity link Poisson GLM with L0 penalty and an
#         optimized lambda using IC on full data
L0glm5 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                lambda = 10^seq(-3,3, length.out = 51), # Use arbitrary sequence
                tune.crit = "bic", tune.meth = "IC", nonnegative = TRUE, normalize = FALSE)
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm5, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (BIC tuning)")

# Case VI: fit nonnegative identity link Poisson GLM with L0 penalty and an
#           optimized lambda using training and validation set
L0glm6 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                lambda = 10^seq(-3,3, length.out = 51), # Use arbitrary sequence
                tune.crit = "bic", tune.meth = "trainval", nonnegative = TRUE, normalize = FALSE)
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm6, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (Training/validation set)")

# Case VII: fit nonnegative identity link Poisson GLM with L0 penalty and an
#           optimized lambda using 3-fold CV
L0glm7 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                lambda = 10^seq(-3,3, length.out = 51), # Use arbitrary sequence
                tune.crit = "bic", tune.meth = "3-fold", nonnegative = TRUE, normalize = FALSE)
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm7, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (3-fold CV)")

# Case VIII: fit nonnegative identity link Poisson GLM with L0 penalty and an
#            optimized lambda using LOOCV
L0glm8 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                lambda = 10^seq(-3,3, length.out = 51), # Use arbitrary sequence
                tune.meth = "loocv", nonnegative = TRUE, normalize = FALSE)
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm8, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (LOOCV)")
}

# Case IX: fit nonnegative identity link Poisson GLM with L0 penalty and a
#          prespecify lambda using BIC
L0glm9 <- L0glm(formula = "y ~ 0 + .", data = data.frame(X, y = y), family = poisson(identity),
                lambda = "aic", # set lambda that minimize the expected BIC
                nonnegative = TRUE, normalize = FALSE)
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm9, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (prespecified with BIC)")
}
\references{
Frommlet, F. and G., Nuel. (2016) An adaptive ridge procedure for L0 regularization. PloS one.

Hastie, T. J. and Pregibon, D. (1992) Generalized linear models. Chapter 6 of Statistical Models in S eds J. M. Chambers and T. J. Hastie, Wadsworth & Brooks/Cole.

McCullagh P. and Nelder, J. A. (1989) Generalized Linear Models. London: Chapman and Hall.
}
\seealso{
\code{\link{control.l0.gen}}, \code{\link{control.iwls.gen}},
\code{\link{control.fit.gen}}
}
\author{
Tom Wenseleers, Christophe Vanderaa
}
