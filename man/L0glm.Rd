% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/L0glm.R
\name{L0glm}
\alias{L0glm}
\alias{L0glm.fit}
\alias{glm.iwls}
\title{Fitting Constrained L0 Penalized Generalized Linear Models}
\usage{
L0glm(X, y, weights = rep(1, length(y)), family = gaussian(identity),
  start = NULL, intercept = TRUE, lambda = 0, no.pen = 0,
  nonnegative = FALSE, control.l0 = list(), control.iwls = list(),
  control.fit = list(), post.filter.fn = function(u) return(u),
  tune.meth = "none", tune.crit = "bic", seed = NULL,
  verbose = TRUE)

L0glm.fit(X, y, weights = rep(1, length(y)),
  family = poisson(identity), lambda = 0, start = NULL,
  nonnegative = FALSE, post.filter.fn = function(u) return(u),
  control.l0 = list(maxit = 100, rel.tol = 1e-04, delta = 1e-05, gamma =
  2, warn = FALSE), control.iwls = list(maxit = 100, rel.tol = 1e-04,
  thresh = 1e-05, warn = FALSE), control.fit = list(maxit = 10,
  block.size = NULL, tol = 1e-07))

glm.iwls(X, y, weights, family, start = NULL, lambda = rep(0, ncol(X)),
  nonnegative = FALSE, control.iwls = list(maxit = 100, rel.tol =
  1e-04, thresh = 1e-05, warn = FALSE), control.fit = list(maxit = 10,
  block.size = NULL, tol = 1e-07), converged_set = rep(FALSE, ncol(X)))
}
\arguments{
\item{X}{a design matrix of dimension \code{n * p}.}

\item{y}{a vector of obersvation of length \code{n}.}

\item{weights}{a vector of observation weights ("prior weights") of length
\code{n}.}

\item{family}{a description of the error distribution and link function to be
used in the model. This can be a character string naming a family function, a
family function or the result of a call to a family function. (See
\code{stats::family} for details of family functions.)}

\item{start}{a vector of starting values for the coefficients to estimate.
Must be of length \code{p}.}

\item{intercept}{whether or not to include a constant intercept term in the
provided design matrix X. The intercept is not penalized.}

\item{lambda}{either a scalar, a vector of numerics, or a character (see
details). Set \code{lambda = 0} to disable penalization.}

\item{no.pen}{a vector of coefficient indices (intercept excluded) that should \strong{not}
be penalized.}

\item{nonnegative}{a logical indicating whether nonnegativity constraints should be applied.}

\item{control.l0}{list of parameters controling the L0 penalty loop (see details). The list
should contain the following elements:
\itemize{
\item{\code{maxit}: maximum number of iterations. Set to 1 for ridge penalty
(if \code{start == NULL}) or adaptive ridge penalty (if \code{start} != NULL).}
\item{\code{rel.tol}: coefficients are update until the relative difference
between two iteration is smaller than this threshold. The relative difference
is defined as
\eqn{2 \frac{|coef_i^{(k-1)} - coef_i^{(k)}|}{coef_i^{(k-1)} + coef_i^{(k)}}}}
\item{\code{delta}, \code{gamma}: parameters for computing the adaptive
weights during the penalization.}
\item{\code{warn}: should warnings from the AR iteration be produced ?}
}
Missing values will be filled with defaults (see \code{\link{control.l0.gen}})}

\item{control.iwls}{list of parameters controling the IWLS loop (see details). The list should
contain the following elements:
\itemize{
\item{\code{maxit}: maximum number of iterations}
\item{\code{rel.tol}: coefficients are update until the relative difference
between two iteration is smaller than this threshold. The relative difference
is defined as
\eqn{2 \frac{|coef_i^{(k-1)} - coef_i^{(k)}|}{coef_i^{(k-1)} + coef_i^{(k)}}}}
\item{\code{thresh}: a threshold under which the fitted coefficients are
clipped to 0.}
\item{\code{warn}: should warnings from the IWLS iteration be produced ?}
}
Missing values will be filled with defaults (see \code{\link{control.iwls.gen}})}

\item{control.fit}{list of parameters controling the core fitting algoritm (see details). The
list should contain the following elements:
\itemize{
\item{\code{maxit}: maximum number of iterations}
\item{\code{block.size}: number of covariates to fit simultaneously. If
\code{block.size < p}, the fit is performed in different blocks which is
updated cyclically. }
\item{\code{tol}: stop iteration when the difference in coefficients between
iterations is smaller than this threshold. The coefficient difference is
defined as:
\eqn{\frac{\|coefs^{(k-1)} - coefs^{(k)}}{\|coefs^{(k-1)}\|}}}
}
Missing values will be filled with defaults (see \code{\link{control.fit.gen}})}

\item{post.filter.fn}{A function that performs post filtering to the coefficients at the end of the
fit. It should require a single argument that is the vector of coefficients.
Note that lambda tuning will be performed with the processed coefficients, so
the selected lambda will be influence by the filtering step. Default: no
filtering.}

\item{tune.meth}{lambda selection method (see details). It should be one of \code{"none"},
\code{"IC"}, \code{"loocv"}, \code{"k-fold"} (where
k should be a numeric indicating the number of folds to use).}

\item{tune.crit}{the criterion based on which to select the optimal lambda. Should be one of
\code{"all"}, \code{"bic"}, \code{"aic"}, \code{"loglik"}, \code{"loocv"},
\code{"rss"}, \code{"aicc"}, \code{"ebic"}, \code{"hq"}, \code{"ric"},
\code{"mric"}, \code{"cic"}, \code{"bicg"}, \code{"bicq"}) # TODO adapt}

\item{seed}{a seed to use in case of \code{"k-fold"} CV.}

\item{verbose}{print algorithm progression to console ?}

\item{converged_set}{a vector of length \code{p} with logicals indicating whether the
corresponding coefficient already converged (\code{TRUE}) or not
(\code{FALSE}).}
}
\value{
\code{L0glm} returns an "L0glm" object which contains the following
elements:
\item{\code{call}}{The call that produced this object.}
\item{\code{coefficients}}{a vector of fitted coefficients.}
\item{\code{constraint}}{the constrained used for fitting. Either "none" if
no constraint was applied or "nonneg" for nonnegative fits.}
\item{\code{converged.iwls}}{Did the last iteration of IWLS converged?}
\item{\code{converged.l0}}{Did the adaptive ridge converged?}
\item{\code{deviance}}{a list containing:}
\itemize{
\item{\code{residual.df}: residual degrees of freedom of the model}
\item{\code{null.df}: residual degrees of freedom of the null model}
\item{\code{residual.deviance}: \eqn{D_{res} = 2 (loglik(saturated) - loglik(model))}}
\item{\code{null.deviance}: \eqn{D_{null} = 2 (loglik(saturated) - loglik(null))}}
\item{\code{D.squared}: explained deviance = \eqn{1 - \frac{D_{res}}{D_{null}}}}#'
}
\item{\code{df}}{a list containing the \code{edf} effective degrees of freedom,
and \code{rdf} residual degree of freedom of the fitted model.}
\item{\code{eta}}{a vector with the fitted response on the link scale.}
\item{\code{family}}{The error structure used to fit the data.}
\item{\code{fitted.values}}{a vector with the fitted response.}
\item{\code{IC}}{a vector with IC values and other goodness of fit criteria.
Currently implemented are: \code{loglik}, \code{rss}, \code{aic}, \code{aicc},
\code{bic}, \code{ebic}, \code{hq}, \code{ric}, \code{mric}, \code{cic},
\code{bicg}, \code{bicq}.}
\item{\code{iter.iwls}}{A vector of length \code{iter.l0} containing the
number of iterations performed for every IWLS fit.}
\item{\code{iter.l0}}{The number of adaptive ridge iterations.}
\item{\code{lambda}}{The lambda used for the the adaptive ridge. This is a
vector of length \code{p} which may contain zeros for unpenalized coefficients.}
\item{\code{lambda.tune}}{TODO}
\item{\code{lambda.w}}{The converged lambda weights from the adaptive ridge
iteration. This is a vector of length \code{p} with coefficient specific
weights.}
\item{\code{prior.coefficients}}{a vector with the supplied prior values of the
coefficients. NULL if no prior was supplied.}
\item{\code{prior.weights}}{a vector with the initial observation weights}
\item{\code{residuals}}{a vector of residuals.}
\item{\code{timing}}{time (in sec) taken for fitting the model (after lambda tuning).}
\item{\code{weights}}{a vector of converged IWNNLS weights. This is a vector
of length \code{n}.}
}
\description{
Fit a generalized linear model with nonnegativity contraints and ridge, adaptive ridge,
or best subset (L0) penalty on the coefficients. The function uses an iteratively reweighted
nonnegative least squares (IWNNLS) algorithm, which was adapted from the
regular IRLS algorithms to solve GLMs (cf. McCullach & Nelder 1989).
}
\details{
\strong{Structure of the algorithm}

\code{L0glm} starts with lambda tuning (see below) and tries to select the
best lambda out of the serie of lambda supplied by the user, given a
tuning method and criterion. If a single lambda value is supplied, this
step is skipped. The best lambda is then used to fit the penalized GLM. The
algorithm contains 3 main nest loops. From high level to low level:
\itemize{
\item{\strong{Adaptive ridge for L0 penalty:} the L0 penalty is approximated
by iteratively fitting an adaptive ridge and update the penalty weights based
on the fitted coefficient from the previous update. The penalty weights are
updated using the formula \eqn{\frac{1}{(|\beta|^{\gamma} + \delta^{\gamma})}}
(Frommlet et Nuel 2016). When \code{control.l0$maxit == 1}, this boils
down}
\item{\strong{GLM fitting using IWLS:} TODO + TODO ref}
\item{\strong{Block-wise (NN)LS fitting:} TODO}
}

Information criteria and other goodness of fit of measures are computed based
on the fitted coefficients.

\strong{Lambda tuning}

Lambda can be specified in 3 ways:

\itemize{
\item{\strong{Scalar}: lambda is the penalty factor used for the ridge,
adaptive ridge, or best subset regression.}

\item{\strong{Numerical vector}: every value of lambda will be used as penalty
factor for the ridge, adaptive ridge, or best subset regression, separately.
The lambda that leads to the best fit according to the provided selection
method and  criteria is kept and used to fit the model. If \code{tune.meth} is set
to \code{"none"}, the fit will be performed with every lambda and hence the
\code{"L0glm"} object will contain an \code{p x length(lambda)} matrix of
coefficients and \code{n x length(lambda)} matrix of fitted values.}

\item{\strong{Character}}: In the case that L0 penalty is required (\emph{i.e.}
\code{control.l0$maxit > 1}), lambda can be supplied as the information
criterion to optimize. Possible values are \code{"aic"} (\eqn{\lambda = 2}),
\code{"bic"} (\eqn{\lambda = ln(n)}), \code{"ebic"} (\eqn{\lambda = 2 ln(p)   (1-ln(n)/(2 * ln(p)))*2*log(p)}), TODO adapt ebic
\code{"hq"} (\eqn{\lambda = 2 ln(ln(n))}), or \code{"bicq"} (\eqn{\lambda =
ln(n) - 2 ln(\frac{q}{1-q})}).

}

The lambda tuning relies on different methods: TODO

Lambda upper bound: TODO + TODO ref (L0Learn?)
}
\section{Functions}{
\itemize{
\item \code{L0glm.fit}: fits an L0 penalized regression using the adaptive ridge algorithm (Frommlet
et Nuel 2016). The function contains minimal code for fitting the adaptive
ridge and is called by the higher level \code{L0glm}.

\item \code{glm.iwls}: fits a GLM using iteratively weighted least squares (McCullagh and Nelder 1989). Note that
\code{lambda} should be a vector of length \code{p} and no lambda tuning is
performed.
}}

\note{
When a lambda is supplied as vector with no tuning method (\code{tune.meth == "none"}),
the function returns an object of class \code{tune.L0glm}. This contains
\code{coefficients} (a \code{p} by \code{length(lambda)} matrix), \code{fitted.values}
(a \code{n} by \code{length(lambda)} matrix), \code{family}, and \code{prior.weights}.
}
\examples{
# Simulate data
sim <- simulate_spike_train()
X <- sim$X
y <- sim$y

# Case I: fit nonnegative identity link Poisson GLM with no penalty
L0glm1 <- L0glm(X = X, y = y, family = poisson(identity), intercept = FALSE,
                lambda = 0, tune.meth = "none", nonnegative = TRUE,
                control.iwls = list(maxit = 100), # default
                control.l0 = list(maxit = 1, delta = 1E-2, gamma = 1.8))
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm1, a.true = sim$a,
                     main="Ground truth vs L0glm estimates")

# Case II: fit nonnegative identity link Poisson GLM with ridge penalty
L0glm2 <- L0glm(X = X, y = y, family = poisson(identity), intercept = FALSE,
                lambda = 1, tune.meth = "none", nonnegative = TRUE,
                control.iwls = list(maxit = 100), # default
                control.l0 = list(maxit = 1))
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm2, a.true = sim$a,
                     main="Ground truth vs L0glm estimates (with ridge penalty)")

# Case III: fit nonnegative identity link Poisson GLM with adaptive ridge penalty
library(nnls)
a0 <- nnls(A = X*sqrt(1/(y+0.1)),
           b = y*sqrt(1/(y+0.1)))$x
L0glm3 <- L0glm(X = X, y = y, family = poisson(identity), intercept = FALSE,
                start = a0, lambda = 1, tune.meth = "none", nonnegative = TRUE,
                control.iwls = list(maxit = 100), # default
                control.l0 = list(maxit = 1))
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm3, a.true = sim$a,
                     main="Ground truth vs L0glm estimates (with adaptive ridge penalty)")

# Case IV: fit nonnegative identity link Poisson GLM with L0 penalty and a fixed
#          lambda (no lambda selection)
L0glm4 <- L0glm(X = X, y = y, family = poisson(identity), intercept = FALSE,
                lambda = 1, tune.meth = "none", nonnegative = TRUE,
                control.iwls = list(maxit = 100), # default
                control.l0 = list(maxit = 100)) # default
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm4, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates")

\donttest{ # Code below is computationally costly
# Case V: fit nonnegative identity link Poisson GLM with L0 penalty and an
#           optimized lambda using IC on full data
L0glm5 <- L0glm(X = X, y = y, family = poisson(identity),
                lambda = 10^seq(-3,3, length.out = 51), # Use arbitrary sequence
                tune.crit = "bic", tune.meth = "IC", nonnegative = TRUE,
                control.iwls = list(maxit = 100), # default
                control.l0 = list(maxit = 100)) # default
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm5, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (BIC tuning)")

# Case VI: fit nonnegative identity link Poisson GLM with L0 penalty and an
#           optimized lambda using training and validation set
L0glm6 <- L0glm(X = X, y = y, family = poisson(identity),
                lambda = 10^seq(-3,3, length.out = 51), # Use arbitrary sequence
                tune.crit = "bic", tune.meth = "trainval", nonnegative = TRUE,
                control.iwls = list(maxit = 100), # default
                control.l0 = list(maxit = 100)) # default
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm6, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (3-fold CV)")

# Case VII: fit nonnegative identity link Poisson GLM with L0 penalty and an
#           optimized lambda using 3-fold CV
L0glm7 <- L0glm(X = X, y = y, family = poisson(identity),
                lambda = 10^seq(-3,3, length.out = 51), # Use arbitrary sequence
                tune.crit = "bic", tune.meth = "3-fold", nonnegative = TRUE,
                control.iwls = list(maxit = 100), # default
                control.l0 = list(maxit = 100)) # default
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm7, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (3-fold CV)")

# Case VIII: fit nonnegative identity link Poisson GLM with L0 penalty and an
#           optimized lambda using LOOCV
L0glm8 <- L0glm(X = X, y = y, family = poisson(identity),
                lambda = 10^seq(-3,3, length.out = 51), # Use arbitrary sequence
                tune.meth = "loocv", nonnegative = TRUE,
                control.iwls = list(maxit = 100), # default
                control.l0 = list(maxit = 100)) # default
plot_L0glm_benchmark(x = sim$x, y = y, fit = L0glm8, a.true = sim$a,
                     main="Ground truth vs L0 penalized L0glm estimates (LOOCV)")
}
}
\references{
Frommlet, F. and G., Nuel. (2016) An adaptive ridge procedure for L0 regularization. PloS one.

Hastie, T. J. and Pregibon, D. (1992) Generalized linear models. Chapter 6 of Statistical Models in S eds J. M. Chambers and T. J. Hastie, Wadsworth & Brooks/Cole.

McCullagh P. and Nelder, J. A. (1989) Generalized Linear Models. London: Chapman and Hall.
}
\seealso{
\code{\link{control.l0.gen}}, \code{\link{control.iwls.gen}},
\code{\link{control.fit.gen}}
}
\author{
Tom Wenseleers, Christophe Vanderaa
}
